{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mne.stats import fdr_correction\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random \n",
    "import subprocess\n",
    "import matplotlib as mpl\n",
    "from matplotlib import animation\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('ticks')\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59851663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples metadata\n",
    "filtered_reads_samples_filterdis  = pd.read_pickle('.../metadata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use human/bacterial protein abundance profile to run RF\n",
    "all_uniref_human_profile = glob('hp_abun/*human_cluster_filter.pkl')\n",
    "all_uniref_human_profile_df = [pd.read_pickle(x) for x in all_uniref_human_profile]\n",
    "\n",
    "# all study names\n",
    "study_name = pd.DataFrame(all_uniref_human_profile)[0].str.replace('hp_abun/','').str.replace('_human_cluster_filter.pkl','').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8573410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tuned hyperparams from gridsearch\n",
    "best_para = pd.read_pickle('RF_final/best_hyperparam.pkl')\n",
    "best_para = best_para.replace(np.nan, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21db257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach \"labels\" to the metagenomic samples \n",
    "def return_all_factorized():\n",
    "    all_df_study = []\n",
    "    for i in range(len(study_name)):\n",
    "        temp = all_uniref_human_profile_df[i].reset_index()\\\n",
    "        .merge(filtered_reads_samples_filterdis[filtered_reads_samples_filterdis.study_name\\\n",
    "        == study_name[i]][['sample_id','study_condition']].dropna(), right_on = 'sample_id', \\\n",
    "        left_on = 'index').drop('index', axis = 1).rename(columns = {'study_condition':'y'})\n",
    "        temp.index = temp.sample_id\n",
    "        temp.drop('sample_id', axis = 1, inplace = True)\n",
    "        temp.loc[temp['y']!='control', 'y'] = 1\n",
    "        temp.loc[temp['y']=='control', 'y'] = 0\n",
    "        temp['y'] = temp['y'].astype('int')\n",
    "        temp = temp.reset_index(drop = True)\n",
    "        all_df_study.append(temp)\n",
    "    return all_df_study\n",
    "\n",
    "all_uniref_human_profile_df_fac = return_all_factorized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24e7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# caculate the enrichment scores \n",
    "def significance(contingency_table):\n",
    "    odds, fisher_pvalue = stats.fisher_exact(contingency_table)\n",
    "    if (contingency_table.min()>=5) and (contingency_table.mean()>=5):\n",
    "            chi, chi_pvalue, _, _ = stats.chi2_contingency(contingency_table)\n",
    "            return odds, chi, chi_pvalue\n",
    "    else:\n",
    "        return odds, np.nan, fisher_pvalue\n",
    "    \n",
    "def calculate_fi(data, name='study', y_label='condition', output_dir='.'):\n",
    "\n",
    "    sample_names = data.index.tolist()\n",
    "    feature_names = [c for c in data.columns if c!='y']\n",
    "    X = data[feature_names].values\n",
    "    y = data['y'].astype(int).values\n",
    "    \n",
    "    # Fisher exact test/chi2 test\n",
    "    ypos_xpos = ((X>0).astype(int)[y==1]==1).sum(axis=0)\n",
    "    yneg_xneg = ((X>0).astype(int)[y==0]==0).sum(axis=0)\n",
    "    ypos_xneg = ((X>0).astype(int)[y==1]==0).sum(axis=0)\n",
    "    yneg_xpos = ((X>0).astype(int)[y==0]==1).sum(axis=0)\n",
    "    contingency_tables = np.array([[[a,b],\n",
    "                                    [c,d]] \n",
    "                                   for a,b,c,d in \n",
    "                                   zip(ypos_xpos, ypos_xneg, \n",
    "                                       yneg_xpos, yneg_xneg)])\n",
    "\n",
    "    odds, chi ,pvalues = zip(*[significance(table) \n",
    "                               for table in contingency_tables])\n",
    "\n",
    "    statistics = pd.DataFrame({'protein':feature_names,\n",
    "                               'pos{yx}':ypos_xpos,'pos{y}':ypos_xneg, \n",
    "                               'pos{x}':yneg_xpos,'pos{}':yneg_xneg, \n",
    "                               'odds':odds,'chi':chi ,\n",
    "                               'p':pvalues}).sort_values(by='p')\n",
    "\n",
    "    statistics['LOR'] = statistics['odds'].apply(np.log)\n",
    "    _, statistics['BH_FDR_threshold'] = fdr_correction(statistics['p'])\n",
    "    statistics['Bonferroni_adj_p'] = statistics['p'] * statistics.shape[0]\n",
    "    statistics['Bonferroni_adj_p'] = statistics['Bonferroni_adj_p'].where(statistics['Bonferroni_adj_p']<=1.0, 1.0)  \n",
    "    \n",
    "    real_trials   = []\n",
    "    random_trials = []\n",
    "    \n",
    "    min_samples_leaf = best_para[best_para.study_name == name].min_samples_leaf.values[0]\n",
    "    min_samples_split = best_para[best_para.study_name == name].min_samples_split.values[0]\n",
    "    n_estimators = best_para[best_para.study_name == name].n_estimators.values[0]\n",
    "    max_depth = best_para[best_para.study_name == name].max_depth.values[0]\n",
    "    \n",
    "    for i in range(100):\n",
    "        if max_depth == 'None':\n",
    "            clf = RandomForestClassifier(n_jobs = 10, bootstrap = True, max_features = 'auto',\n",
    "                                     min_samples_leaf = min_samples_leaf,\n",
    "                                    min_samples_split = min_samples_split, \n",
    "                                    n_estimators = n_estimators, class_weight = 'balanced')\n",
    "        else:\n",
    "            clf = RandomForestClassifier(n_jobs = 10, bootstrap = True, max_features = 'auto',\n",
    "                                     min_samples_leaf = min_samples_leaf,\n",
    "                                    min_samples_split = min_samples_split, \n",
    "                                    n_estimators = n_estimators, max_depth = max_depth, class_weight = 'balanced')\n",
    "        \n",
    "        clf.fit(X, y)\n",
    "        real_trials.append(clf.feature_importances_)\n",
    "        \n",
    "        # Simulated Iteration\n",
    "        simulated_y = [int(random.random()<=y.mean()) for i in range(len(y))]\n",
    "        \n",
    "        if max_depth == 'None':\n",
    "            clf = RandomForestClassifier(n_jobs = 10, bootstrap = True, max_features = 'auto',\n",
    "                                     min_samples_leaf = min_samples_leaf,\n",
    "                                    min_samples_split = min_samples_split, \n",
    "                                    n_estimators = n_estimators, class_weight = 'balanced')\n",
    "        else:\n",
    "            clf = RandomForestClassifier(n_jobs = 10, bootstrap = True, max_features = 'auto',\n",
    "                                     min_samples_leaf = min_samples_leaf,\n",
    "                                    min_samples_split = min_samples_split, \n",
    "                                    n_estimators = n_estimators, max_depth = max_depth, class_weight = 'balanced')\n",
    "            \n",
    "        \n",
    "        clf.fit(X, simulated_y)            \n",
    "        random_trials.append(clf.feature_importances_)\n",
    "        \n",
    "\n",
    "    real = pd.DataFrame(real_trials, columns=feature_names)\n",
    "    sim  = pd.DataFrame(random_trials, columns=feature_names)\n",
    "    enrichment = pd.DataFrame({\"real_mean\":real.T.mean(axis=1), \n",
    "                               \"real_std\":real.T.std(axis=1),\n",
    "                               \"sim_mean\":sim.T.mean(axis=1), \n",
    "                               \"sim_std\":sim.T.std(axis=1)})\n",
    "    \n",
    "    out_filename = '{}/{}_{}_final_{}.csv'.format(\n",
    "    output_dir, name, y_label, real.shape[0])\n",
    "        \n",
    "    statistics.set_index('protein')[\n",
    "        ['pos{yx}','pos{y}','pos{x}', 'pos{}','LOR','p','BH_FDR_threshold','Bonferroni_adj_p']\n",
    "    ].join(enrichment[['real_mean','real_std','sim_mean','sim_std']]).sort_values(by='p').to_csv(out_filename)\n",
    "    \n",
    "    print(name, ': done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dceaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the importance ranking and stats \n",
    "for i in range(len(study_name)):\n",
    "    calculate_fi(all_uniref_human_profile_df_fac[i], name=study_name[i], \n",
    "                            output_dir='RF_final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbsubrito3",
   "language": "python",
   "name": "cbsubrito3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
